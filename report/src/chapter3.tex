\newchapter{3}{Глава 3}

\section{Реализация на Python}

Для проверки работоспособности и эффективности подхода к контекстной информации, предложенного во второй главе был написан прототип рекомендательной системы на языке Python.

\subsection{Реализация SVD}

Обычные алгоритмы поиска SVD разложения не подходят для матрицы отзывов, потому что в такой матрице значения многих элементов неизвестны, их предсказание и является задачей системы. Однако, все классические алгоритмы поиска SVD ожидают полную матрицу. Существует два способа решения данной проблемы:

\begin{itemize}
\item Попытаться заполнить пустые ячейки определенными значениями, например, средней оценкой для всех фильмов или нулями. Такой метод вносит неточность в результат разложения и значительно увеличивает объем затрачиевомой памяти для хранения матрицы.
\item Применить метод, предложенный Cимоном Фанком \cite{Funk}, который основан на градиентном спуске.
\end{itemize}

\subsection{FunkSVD}

Суть предложенного Фанком алгоритма заключается в использовани метода стохастического градиентного спуска, используя только известные значения матрицы отзывов. Результатом работы алгоритма будет две матрицы, а не три, как в классическом разложении. Диагональная матрица с сингулярными значениями уже будет инкапсулирована в эти две матрицы.

Для нахождения разложения, используется сохастический градиентный спуск. Каждый признак обучается по отедльности при помощи следующих правил:
\begin{gather*}
    U_{f_i} = U_{f_i} + L(2eI_{f_i} - GU_{f_i}) \\
    I_{f_i} = I_{f_i} + L(2eU_{f_i} - GI_{f_i})
\end{gather*}

Здесь L - это константа, отвечающая за скорость обучения, G - нормализующая константа для борьбы с переобучением, $e = r_{kj} - (U_k, I_j)$ разница между предсказаным значением оценки и настоящим. Поскольку обучение происходит на известных оценках, то и $r_{kj}$ всегда известен.

\section{Оценка эффективности}

Существует несколько методов оценивания работы рекомендательной системы. После того, как были найдены матрицы признаков U и I, выбирается тестовый набор данных, из него берутся оценки пользователей, которые на момент обучения были неизвестны, и система предсказывает эти оценки $\widehat{r_i} = (U_i, I_i)$. Далее высчитываются следующие метрики:

% \begin{gather*}
% \textit{Root Mean Square Error (RMSE)} = \sqrt{\dfrac{1}{n}\sum_i^n (r_i - \widehat{r_i})^2} \\
% \textit{Mean Absolute Error (MAE)} = \sum_i^n |r_i - \widehat{r_i}|
% \end{gather*}

Разница между MAE и RMSE заключается в том, что RMSE намного сильнее реагирует на большие отклонения. 

Были получены следующие значения ошибок:

\begin{center}
  \begin{tabular}{| C{3.5cm} | C{1.5cm} | C{1.5cm} | @{}m{0pt}@{}}
    \hline
     & RMSE & MAE & \\[0.5em] \hline
    SVD & 0.934347 & 0.758373 & \\[1.4em] \hline
    SVD + Context & 0.919411 & 0.753776 & \\[1.4em]
    \hline
  \end{tabular}
\end{center}

Видно, что рекомендательная система, которая учитывает контекстную информацию, способна лучше предсказывать оценки пользователей.

\section{Исходный код}

Далее будет представлен исходный код. Все исходники доступны на \href{https://github.com/Makazone/2ndYear-TermProject}{GitHub}

% \lstinputlisting[language=Python, caption=Реализация SVD]{svd.py}
% \lstinputlisting[language=Python, caption=Реализация SVD с контекстной информацией]{casvd.py}
% \lstinputlisting[language=Python, caption=Реализация MAE, RMSE]{RecSysEvaluator.py}
% \lstinputlisting[language=Python, caption=main]{main.py}
% \lstinputlisting[language=Python, caption=Класс пользователя]{User.py}
% \lstinputlisting[language=Python, caption=Класс фильма]{Film.py}